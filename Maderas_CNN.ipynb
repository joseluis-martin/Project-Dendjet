{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1SpONzPEL28zxUI4ydQpq3Wv4SWMdiu5y",
      "authorship_tag": "ABX9TyN7FF/BGyEh1s0NST+AjFEW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joseluis-martin/Project-Dendjet/blob/main/Maderas_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Importaciones\n",
        "\n",
        "Este bloque inicial carga todas las \"herramientas\" o librer铆as que el programa necesita para funcionar."
      ],
      "metadata": {
        "id": "1xfR4vs3_GjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models # Importamos 'models' para las CNNs\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "import time\n",
        "import os\n",
        "\n",
        "print(\"PyTorch Version:\", torch.__version__)"
      ],
      "metadata": {
        "id": "rDXLn1lJ_JDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `torch, torch.nn, torch.optim`: Forman el n煤cleo de PyTorch. torch se encarga de los tensores (la estructura de datos fundamental), torch.nn (Neural Networks) proporciona las capas de la red neuronal (como la capa de clasificaci贸n), y torch.optim contiene los optimizadores (como AdamW) que ajustan el modelo.\n",
        "\n",
        "* `torchvision`: Es la librer铆a de PyTorch para tareas de visi贸n por computador. datasets nos da acceso a ImageFolder, transforms nos permite procesar las im谩genes, y models contiene arquitecturas cl谩sicas.\n",
        "\n",
        "* `DataLoader`: Una utilidad clave de PyTorch que carga los datos en lotes (batches), los mezcla aleatoriamente (shuffle) y puede usar m煤ltiples n煤cleos de CPU (num_workers) para cargar datos eficientemente.\n",
        "\n",
        "* `numpy`: Una librer铆a para computaci贸n num茅rica. La usamos para convertir los tensores de PyTorch a un formato que scikit-learn pueda entender.\n",
        "\n",
        "* `matplotlib.pyplot` y `seaborn`: Son librer铆as de visualizaci贸n. matplotlib es la base para crear gr谩ficos, y seaborn nos permite crear gr谩ficos estad铆sticos m谩s atractivos, como el mapa de calor de la matriz de confusi贸n.\n",
        "\n",
        "* `sklearn.metrics`: Parte de Scikit-learn, nos proporciona herramientas ya hechas para evaluar el rendimiento del modelo, como classification_report (precisi贸n, recall, f1-score), confusion_matrix, y accuracy_score.\n",
        "\n",
        "* `time` y `os`: Utilidades est谩ndar de Python. time nos permite medir cu谩nto tarda cada 茅poca de entrenamiento, y os nos ayuda a interactuar con el sistema operativo (por ejemplo, para crear carpetas)."
      ],
      "metadata": {
        "id": "YS9j2y54_xU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Configuraci贸n y Par谩metros 锔\n",
        "\n",
        "Esta secci贸n centraliza todas las variables y par谩metros que podr铆as querer ajustar. Tenerlos aqu铆 al principio facilita la experimentaci贸n."
      ],
      "metadata": {
        "id": "dGa0EKokAOIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 隆隆IMPORTANTE!! Ajusta estas rutas a nuestro sistema\n",
        "TRAIN_DIR = '/content/drive/MyDrive/Proyecto_Maderas_Sarcofagos/dataset/train'\n",
        "VAL_DIR = '/content/drive/MyDrive/Proyecto_Maderas_Sarcofagos/dataset/val'\n",
        "TEST_DIR = '/content/drive/MyDrive/Proyecto_Maderas_Sarcofagos/dataset/test'\n",
        "\n",
        "# Par谩metros del entrenamiento\n",
        "NUM_EPOCHS = 15\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "# Configuraci贸n del dispositivo (usar GPU si est谩 disponible)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Usando dispositivo: {DEVICE}\")\n"
      ],
      "metadata": {
        "id": "vnrvWo7GATyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `TRAIN_DIR y VAL_DIR`: Son cadenas de texto que contienen la ruta a tus carpetas de entrenamiento y validaci贸n.\n",
        "\n",
        "* `NUM_EPOCHS`: El n煤mero de veces que el modelo ver谩 el conjunto de datos de entrenamiento completo.\n",
        "\n",
        "* `BATCH_SIZE`: El n煤mero de im谩genes que el modelo procesa a la vez antes de actualizar sus pesos. Un batch size m谩s grande puede acelerar el entrenamiento pero consume m谩s memoria de la GPU.\n",
        "\n",
        "* `LEARNING_RATE`: La \"tasa de aprendizaje\". Controla el tama帽o de los pasos que da el optimizador para corregir los errores. Es uno de los hiperpar谩metros m谩s importantes.\n",
        "\n",
        "* `DEVICE`: Este c贸digo es \"agn贸stico al dispositivo\". Comprueba si tienes una GPU con CUDA disponible (torch.cuda.is_available()) y la selecciona. Si no, usar谩 la CPU. Entrenar en GPU es miles de veces m谩s r谩pido."
      ],
      "metadata": {
        "id": "D-pipacBAcjR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Preparaci贸n de Datos \n",
        "\n",
        "Este bloque se encarga de definir c贸mo se deben cargar y transformar las im谩genes para que sean aptas para el modelo."
      ],
      "metadata": {
        "id": "aupMklSUAsSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformaciones de datos\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Crear datasets\n",
        "try:\n",
        "    train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=train_transforms)\n",
        "    val_dataset = datasets.ImageFolder(VAL_DIR, transform=val_transforms)\n",
        "    test_dataset = datasets.ImageFolder(TEST_DIR, transform=val_transforms)\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Las carpetas del dataset no se encontraron. Por favor, actualiza las rutas.\")\n",
        "    # Crea datos dummy para que el script no falle en un entorno de prueba\n",
        "    for dir_path in [f\"{TRAIN_DIR}/dummy_class\", f\"{VAL_DIR}/dummy_class\", f\"{TEST_DIR}/dummy_class\"]:\n",
        "        if not os.path.exists(dir_path): os.makedirs(dir_path)\n",
        "    from PIL import Image\n",
        "    dummy_img = Image.new('RGB', (100, 100), color='blue')\n",
        "    dummy_img.save(f\"{TRAIN_DIR}/dummy_class/dummy.png\")\n",
        "    dummy_img.save(f\"{VAL_DIR}/dummy_class/dummy.png\")\n",
        "    dummy_img.save(f\"{TEST_DIR}/dummy_class/dummy.png\")\n",
        "    train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=train_transforms)\n",
        "    val_dataset = datasets.ImageFolder(VAL_DIR, transform=val_transforms)\n",
        "    test_dataset = datasets.ImageFolder(TEST_DIR, transform=val_transforms)\n",
        "\n",
        "# Crear DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "# Obtener nombres y n煤mero de clases\n",
        "CLASS_NAMES = train_dataset.classes\n",
        "NUM_CLASSES = len(CLASS_NAMES)\n",
        "print(f\"Dataset encontrado. Clases: {CLASS_NAMES}\")\n"
      ],
      "metadata": {
        "id": "ta4ooouTAqv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `transforms.Compose([...])`: Crea una secuencia de transformaciones que se aplicar谩n a cada imagen.\n",
        "\n",
        "* `train_transforms`: Para los datos de entrenamiento, aplicamos aumento de datos (RandomHorizontalFlip, RandomRotation, ColorJitter) para crear variaciones artificiales y forzar al modelo a aprender las caracter铆sticas esenciales de la madera, no la orientaci贸n o iluminaci贸n espec铆fica de una foto.\n",
        "\n",
        "* `val_transforms`: Para la validaci贸n, no aplicamos aumento de datos, solo los cambios necesarios (Resize, ToTensor, Normalize) para que las im谩genes tengan el formato correcto. Queremos evaluar el modelo en las im谩genes originales, sin alterar.\n",
        "\n",
        "* `datasets.ImageFolder(...)`: Esta es la funci贸n m谩gica que crea el dataset. Recorre las carpetas TRAIN_DIR y VAL_DIR, asume que cada subcarpeta es una clase, y asigna etiquetas num茅ricas autom谩ticamente.\n",
        "\n",
        "* `DataLoader(...)`: Envuelve el dataset y nos permite iterar sobre 茅l en lotes (batch_size) de manera eficiente.\n",
        "\n",
        "* `CLASS_NAMES y NUM_CLASSES`: Extraemos los nombres de las clases (los nombres de las carpetas) y el n煤mero total de clases directamente del dataset. Esto hace que el c贸digo sea adaptable a cualquier n煤mero de maderas que quieras clasificar."
      ],
      "metadata": {
        "id": "-XB8Wi3jAxyM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Definici贸n del del Modelo CNN (ResNet50) \n",
        "\n",
        "Aqu铆 es donde se define y adapta la arquitectura de la red neuronal.\n",
        "\n"
      ],
      "metadata": {
        "id": "NQ5g2LYnBN_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar una arquitectura EfficientNet-B1 con pesos pre-entrenados\n",
        "model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
        "\n",
        "# En EfficientNet, la capa de clasificaci贸n es parte de una secuencia llamada 'classifier'.\n",
        "# La capa lineal que queremos reemplazar es la 煤ltima de esta secuencia.\n",
        "num_ftrs = model.classifier[1].in_features\n",
        "model.classifier[1] = nn.Linear(num_ftrs, NUM_CLASSES)\n",
        "\n",
        "# Mover el modelo a la GPU\n",
        "model.to(DEVICE)\n",
        "\n",
        "# Definir funci贸n de p茅rdida y optimizador (sin cambios)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "8c5VujGrBG7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `models.`: Esta l铆nea carga la arquitectura red correspondiente e inicializa sus pesos con los que aprendi贸 en el gigantesco dataset ImageNet. Esto significa que el modelo ya es un experto en reconocer patrones, texturas y formas visuales.\n",
        "\n",
        "* `num_ftrs = model.fc.in_features`: El c贸digo inspecciona la 煤ltima capa del modelo pre-entrenado (llamada fc) para ver cu谩ntas neuronas de entrada tiene.\n",
        "\n",
        "* `model.fc = nn.Linear(num_ftrs, NUM_CLASSES)`: Esta es la adaptaci贸n clave. Se reemplaza la 煤ltima capa original (que estaba dise帽ada para clasificar 1000 objetos de ImageNet) por una nueva capa lineal. Esta nueva capa tiene el n煤mero correcto de salidas para corresponder a nuestras clases de madera.\n",
        "\n",
        "* `criterion y optimizer`: Se definen la funci贸n de p茅rdida (CrossEntropyLoss), que mide el error del modelo, y el optimizador (AdamW), que se encarga de minimizar ese error ajustando los pesos del modelo."
      ],
      "metadata": {
        "id": "omQFU9yFBRLN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Funci贸n de Evaluaci贸n\n",
        "\n",
        "Esta es una funci贸n auxiliar que hemos creado para mantener el c贸digo limpio. Su 煤nica responsabilidad es medir el rendimiento del modelo en un conjunto de datos, sin entrenarlo."
      ],
      "metadata": {
        "id": "m_tytBerFEIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
        "    return epoch_loss, epoch_acc, all_preds, all_labels"
      ],
      "metadata": {
        "id": "vFyRhUNVFA6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `model.eval()`: Pone el modelo en modo evaluaci贸n (desactiva Dropout, etc.).\n",
        "\n",
        "* `with torch.no_grad()`: Desactiva el c谩lculo de gradientes para acelerar el proceso y ahorrar memoria, ya que aqu铆 no vamos a entrenar.\n",
        "\n",
        "* El resto del c贸digo itera sobre los datos, calcula la p茅rdida y la precisi贸n, y devuelve estos valores."
      ],
      "metadata": {
        "id": "KGYZHVa2FPJ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Bucle Principal de Entrenamiento y Validaci贸n 锔锔\n",
        "\n",
        "Este es el motor del script, donde el aprendizaje realmente ocurre. Itera varias veces (茅pocas) sobre los datos."
      ],
      "metadata": {
        "id": "dZqlQItzFXE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = {'train_loss': [], 'val_loss': [], 'val_accuracy': []}\n",
        "\n",
        "print(\"\\n--- Iniciando Entrenamiento ---\")\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Fase de Entrenamiento\n",
        "    model.train()\n",
        "    running_train_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_train_loss += loss.item() * inputs.size(0)\n",
        "    epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
        "    history['train_loss'].append(epoch_train_loss)\n",
        "\n",
        "    # Fase de Validaci贸n\n",
        "    val_loss, val_acc, _, _ = evaluate_model(model, val_loader, criterion, DEVICE)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_accuracy'].append(val_acc)\n",
        "\n",
        "    epoch_duration = time.time() - start_time\n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Duraci贸n: {epoch_duration:.2f}s | Train Loss: {epoch_train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "print(\"\\n--- Entrenamiento Completado ---\")"
      ],
      "metadata": {
        "id": "2O0PAY7JFVwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Fase de Entrenamiento (model.train()):\n",
        "\n",
        "    * `optimizer.zero_grad()`: Borra los gradientes del paso anterior.\n",
        "\n",
        "    * `outputs = model(inputs)`: Pasa un lote de im谩genes por la red para obtener las predicciones.\n",
        "\n",
        "    * `loss.backward()`: Calcula c贸mo contribuy贸 cada peso del modelo al error (backpropagation).\n",
        "\n",
        "    * `optimizer.step()`: Actualiza los pesos del modelo para reducir el error.\n",
        "\n",
        "* Fase de Validaci贸n: Despu茅s de cada 茅poca de entrenamiento, se llama a la funci贸n evaluate_model sobre los datos de validaci贸n. Esto nos permite monitorizar si el modelo est谩 aprendiendo correctamente y no se est谩 sobreajustando."
      ],
      "metadata": {
        "id": "CACLUHStFe-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Evaluaci贸n Final y Visualizaci贸n \n",
        "\n",
        "Una vez que el entrenamiento ha terminado, esta secci贸n final proporciona un an谩lisis detallado y visual del rendimiento del mejor modelo."
      ],
      "metadata": {
        "id": "FTaim4KwFqWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Realizando Evaluaci贸n Final sobre el Conjunto de Prueba ---\")\n",
        "test_loss, test_acc, test_preds, test_labels = evaluate_model(model, test_loader, criterion, DEVICE)\n",
        "print(f\"Resultado Final: P茅rdida de Prueba: {test_loss:.4f} | Precisi贸n de Prueba: {test_acc:.4f}\\n\")\n",
        "\n",
        "# Reporte de Clasificaci贸n\n",
        "print(\"--- Reporte de Clasificaci贸n (Test Set) ---\")\n",
        "print(classification_report(test_labels, test_preds, target_names=CLASS_NAMES, zero_division=0))\n",
        "\n",
        "# Matriz de Confusi贸n\n",
        "print(\"\\n--- Matriz de Confusi贸n (Test Set) ---\")\n",
        "conf_matrix = confusion_matrix(test_labels, test_preds)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
        "plt.xlabel('Predicci贸n')\n",
        "plt.ylabel('Etiqueta Real')\n",
        "plt.title('Matriz de Confusi贸n sobre el Conjunto de Prueba')\n",
        "plt.show()\n",
        "\n",
        "# Gr谩ficas del historial de entrenamiento\n",
        "print(\"\\n--- Visualizaci贸n del Historial de Entrenamiento ---\")\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history['train_loss'], label='P茅rdida de Entrenamiento')\n",
        "plt.plot(history['val_loss'], label='P茅rdida de Validaci贸n')\n",
        "plt.xlabel('pocas'); plt.ylabel('P茅rdida'); plt.title('Evoluci贸n de la P茅rdida'); plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history['val_accuracy'], label='Precisi贸n de Validaci贸n')\n",
        "plt.xlabel('pocas'); plt.ylabel('Precisi贸n'); plt.title('Evoluci贸n de la Precisi贸n'); plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q1GDTYB7FpRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `evaluate_model(model, test_loader, ...)`: Se llama a la funci贸n de evaluaci贸n una 煤ltima vez, pero con los datos de prueba.\n",
        "\n",
        "* `classification_report`: Muestra m茅tricas detalladas como la precisi贸n y el recall para cada clase de madera, permiti茅ndonos ver si el modelo es mejor reconociendo una especie que otra.\n",
        "\n",
        "* `confusion_matrix`: Se visualiza como un mapa de calor. La diagonal principal muestra los aciertos. Los n煤meros fuera de la diagonal muestran los errores de clasificaci贸n (por ejemplo, cu谩ntas veces confundi贸 \"cedro\" con \"acacia\").\n",
        "\n",
        "* Gr谩ficas de Historial: Se dibujan las curvas de p茅rdida y precisi贸n a lo largo de las 茅pocas. Estos gr谩ficos son vitales para diagnosticar c贸mo fue el entrenamiento y para detectar problemas como el sobreajuste."
      ],
      "metadata": {
        "id": "uGgKxRvvFwtP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bxISv2cOuu5x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}