{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1SpONzPEL28zxUI4ydQpq3Wv4SWMdiu5y",
      "authorship_tag": "ABX9TyN7FF/BGyEh1s0NST+AjFEW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joseluis-martin/Project-Dendjet/blob/main/Maderas_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Importaciones\n",
        "\n",
        "Este bloque inicial carga todas las \"herramientas\" o librerías que el programa necesita para funcionar."
      ],
      "metadata": {
        "id": "1xfR4vs3_GjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models # Importamos 'models' para las CNNs\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "import time\n",
        "import os\n",
        "\n",
        "print(\"PyTorch Version:\", torch.__version__)"
      ],
      "metadata": {
        "id": "rDXLn1lJ_JDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `torch, torch.nn, torch.optim`: Forman el núcleo de PyTorch. torch se encarga de los tensores (la estructura de datos fundamental), torch.nn (Neural Networks) proporciona las capas de la red neuronal (como la capa de clasificación), y torch.optim contiene los optimizadores (como AdamW) que ajustan el modelo.\n",
        "\n",
        "* `torchvision`: Es la librería de PyTorch para tareas de visión por computador. datasets nos da acceso a ImageFolder, transforms nos permite procesar las imágenes, y models contiene arquitecturas clásicas.\n",
        "\n",
        "* `DataLoader`: Una utilidad clave de PyTorch que carga los datos en lotes (batches), los mezcla aleatoriamente (shuffle) y puede usar múltiples núcleos de CPU (num_workers) para cargar datos eficientemente.\n",
        "\n",
        "* `numpy`: Una librería para computación numérica. La usamos para convertir los tensores de PyTorch a un formato que scikit-learn pueda entender.\n",
        "\n",
        "* `matplotlib.pyplot` y `seaborn`: Son librerías de visualización. matplotlib es la base para crear gráficos, y seaborn nos permite crear gráficos estadísticos más atractivos, como el mapa de calor de la matriz de confusión.\n",
        "\n",
        "* `sklearn.metrics`: Parte de Scikit-learn, nos proporciona herramientas ya hechas para evaluar el rendimiento del modelo, como classification_report (precisión, recall, f1-score), confusion_matrix, y accuracy_score.\n",
        "\n",
        "* `time` y `os`: Utilidades estándar de Python. time nos permite medir cuánto tarda cada época de entrenamiento, y os nos ayuda a interactuar con el sistema operativo (por ejemplo, para crear carpetas)."
      ],
      "metadata": {
        "id": "YS9j2y54_xU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Configuración y Parámetros ⚙️\n",
        "\n",
        "Esta sección centraliza todas las variables y parámetros que podrías querer ajustar. Tenerlos aquí al principio facilita la experimentación."
      ],
      "metadata": {
        "id": "dGa0EKokAOIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ¡¡IMPORTANTE!! Ajusta estas rutas a nuestro sistema\n",
        "TRAIN_DIR = '/content/drive/MyDrive/Proyecto_Maderas_Sarcofagos/dataset/train'\n",
        "VAL_DIR = '/content/drive/MyDrive/Proyecto_Maderas_Sarcofagos/dataset/val'\n",
        "TEST_DIR = '/content/drive/MyDrive/Proyecto_Maderas_Sarcofagos/dataset/test'\n",
        "\n",
        "# Parámetros del entrenamiento\n",
        "NUM_EPOCHS = 15\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "# Configuración del dispositivo (usar GPU si está disponible)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Usando dispositivo: {DEVICE}\")\n"
      ],
      "metadata": {
        "id": "vnrvWo7GATyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `TRAIN_DIR y VAL_DIR`: Son cadenas de texto que contienen la ruta a tus carpetas de entrenamiento y validación.\n",
        "\n",
        "* `NUM_EPOCHS`: El número de veces que el modelo verá el conjunto de datos de entrenamiento completo.\n",
        "\n",
        "* `BATCH_SIZE`: El número de imágenes que el modelo procesa a la vez antes de actualizar sus pesos. Un batch size más grande puede acelerar el entrenamiento pero consume más memoria de la GPU.\n",
        "\n",
        "* `LEARNING_RATE`: La \"tasa de aprendizaje\". Controla el tamaño de los pasos que da el optimizador para corregir los errores. Es uno de los hiperparámetros más importantes.\n",
        "\n",
        "* `DEVICE`: Este código es \"agnóstico al dispositivo\". Comprueba si tienes una GPU con CUDA disponible (torch.cuda.is_available()) y la selecciona. Si no, usará la CPU. Entrenar en GPU es miles de veces más rápido."
      ],
      "metadata": {
        "id": "D-pipacBAcjR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Preparación de Datos 💾\n",
        "\n",
        "Este bloque se encarga de definir cómo se deben cargar y transformar las imágenes para que sean aptas para el modelo."
      ],
      "metadata": {
        "id": "aupMklSUAsSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformaciones de datos\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Crear datasets\n",
        "try:\n",
        "    train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=train_transforms)\n",
        "    val_dataset = datasets.ImageFolder(VAL_DIR, transform=val_transforms)\n",
        "    test_dataset = datasets.ImageFolder(TEST_DIR, transform=val_transforms)\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Las carpetas del dataset no se encontraron. Por favor, actualiza las rutas.\")\n",
        "    # Crea datos dummy para que el script no falle en un entorno de prueba\n",
        "    for dir_path in [f\"{TRAIN_DIR}/dummy_class\", f\"{VAL_DIR}/dummy_class\", f\"{TEST_DIR}/dummy_class\"]:\n",
        "        if not os.path.exists(dir_path): os.makedirs(dir_path)\n",
        "    from PIL import Image\n",
        "    dummy_img = Image.new('RGB', (100, 100), color='blue')\n",
        "    dummy_img.save(f\"{TRAIN_DIR}/dummy_class/dummy.png\")\n",
        "    dummy_img.save(f\"{VAL_DIR}/dummy_class/dummy.png\")\n",
        "    dummy_img.save(f\"{TEST_DIR}/dummy_class/dummy.png\")\n",
        "    train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=train_transforms)\n",
        "    val_dataset = datasets.ImageFolder(VAL_DIR, transform=val_transforms)\n",
        "    test_dataset = datasets.ImageFolder(TEST_DIR, transform=val_transforms)\n",
        "\n",
        "# Crear DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "# Obtener nombres y número de clases\n",
        "CLASS_NAMES = train_dataset.classes\n",
        "NUM_CLASSES = len(CLASS_NAMES)\n",
        "print(f\"Dataset encontrado. Clases: {CLASS_NAMES}\")\n"
      ],
      "metadata": {
        "id": "ta4ooouTAqv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `transforms.Compose([...])`: Crea una secuencia de transformaciones que se aplicarán a cada imagen.\n",
        "\n",
        "* `train_transforms`: Para los datos de entrenamiento, aplicamos aumento de datos (RandomHorizontalFlip, RandomRotation, ColorJitter) para crear variaciones artificiales y forzar al modelo a aprender las características esenciales de la madera, no la orientación o iluminación específica de una foto.\n",
        "\n",
        "* `val_transforms`: Para la validación, no aplicamos aumento de datos, solo los cambios necesarios (Resize, ToTensor, Normalize) para que las imágenes tengan el formato correcto. Queremos evaluar el modelo en las imágenes originales, sin alterar.\n",
        "\n",
        "* `datasets.ImageFolder(...)`: Esta es la función mágica que crea el dataset. Recorre las carpetas TRAIN_DIR y VAL_DIR, asume que cada subcarpeta es una clase, y asigna etiquetas numéricas automáticamente.\n",
        "\n",
        "* `DataLoader(...)`: Envuelve el dataset y nos permite iterar sobre él en lotes (batch_size) de manera eficiente.\n",
        "\n",
        "* `CLASS_NAMES y NUM_CLASSES`: Extraemos los nombres de las clases (los nombres de las carpetas) y el número total de clases directamente del dataset. Esto hace que el código sea adaptable a cualquier número de maderas que quieras clasificar."
      ],
      "metadata": {
        "id": "-XB8Wi3jAxyM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Definición del del Modelo CNN (ResNet50) 🧠\n",
        "\n",
        "Aquí es donde se define y adapta la arquitectura de la red neuronal.\n",
        "\n"
      ],
      "metadata": {
        "id": "NQ5g2LYnBN_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar una arquitectura EfficientNet-B1 con pesos pre-entrenados\n",
        "model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
        "\n",
        "# En EfficientNet, la capa de clasificación es parte de una secuencia llamada 'classifier'.\n",
        "# La capa lineal que queremos reemplazar es la última de esta secuencia.\n",
        "num_ftrs = model.classifier[1].in_features\n",
        "model.classifier[1] = nn.Linear(num_ftrs, NUM_CLASSES)\n",
        "\n",
        "# Mover el modelo a la GPU\n",
        "model.to(DEVICE)\n",
        "\n",
        "# Definir función de pérdida y optimizador (sin cambios)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "8c5VujGrBG7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `models.`: Esta línea carga la arquitectura red correspondiente e inicializa sus pesos con los que aprendió en el gigantesco dataset ImageNet. Esto significa que el modelo ya es un experto en reconocer patrones, texturas y formas visuales.\n",
        "\n",
        "* `num_ftrs = model.fc.in_features`: El código inspecciona la última capa del modelo pre-entrenado (llamada fc) para ver cuántas neuronas de entrada tiene.\n",
        "\n",
        "* `model.fc = nn.Linear(num_ftrs, NUM_CLASSES)`: Esta es la adaptación clave. Se reemplaza la última capa original (que estaba diseñada para clasificar 1000 objetos de ImageNet) por una nueva capa lineal. Esta nueva capa tiene el número correcto de salidas para corresponder a nuestras clases de madera.\n",
        "\n",
        "* `criterion y optimizer`: Se definen la función de pérdida (CrossEntropyLoss), que mide el error del modelo, y el optimizador (AdamW), que se encarga de minimizar ese error ajustando los pesos del modelo."
      ],
      "metadata": {
        "id": "omQFU9yFBRLN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Función de Evaluación\n",
        "\n",
        "Esta es una función auxiliar que hemos creado para mantener el código limpio. Su única responsabilidad es medir el rendimiento del modelo en un conjunto de datos, sin entrenarlo."
      ],
      "metadata": {
        "id": "m_tytBerFEIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
        "    return epoch_loss, epoch_acc, all_preds, all_labels"
      ],
      "metadata": {
        "id": "vFyRhUNVFA6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `model.eval()`: Pone el modelo en modo evaluación (desactiva Dropout, etc.).\n",
        "\n",
        "* `with torch.no_grad()`: Desactiva el cálculo de gradientes para acelerar el proceso y ahorrar memoria, ya que aquí no vamos a entrenar.\n",
        "\n",
        "* El resto del código itera sobre los datos, calcula la pérdida y la precisión, y devuelve estos valores."
      ],
      "metadata": {
        "id": "KGYZHVa2FPJ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Bucle Principal de Entrenamiento y Validación 🏋️‍♂️\n",
        "\n",
        "Este es el motor del script, donde el aprendizaje realmente ocurre. Itera varias veces (épocas) sobre los datos."
      ],
      "metadata": {
        "id": "dZqlQItzFXE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = {'train_loss': [], 'val_loss': [], 'val_accuracy': []}\n",
        "\n",
        "print(\"\\n--- Iniciando Entrenamiento ---\")\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Fase de Entrenamiento\n",
        "    model.train()\n",
        "    running_train_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_train_loss += loss.item() * inputs.size(0)\n",
        "    epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
        "    history['train_loss'].append(epoch_train_loss)\n",
        "\n",
        "    # Fase de Validación\n",
        "    val_loss, val_acc, _, _ = evaluate_model(model, val_loader, criterion, DEVICE)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_accuracy'].append(val_acc)\n",
        "\n",
        "    epoch_duration = time.time() - start_time\n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Duración: {epoch_duration:.2f}s | Train Loss: {epoch_train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "print(\"\\n--- Entrenamiento Completado ---\")"
      ],
      "metadata": {
        "id": "2O0PAY7JFVwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Fase de Entrenamiento (model.train()):\n",
        "\n",
        "    * `optimizer.zero_grad()`: Borra los gradientes del paso anterior.\n",
        "\n",
        "    * `outputs = model(inputs)`: Pasa un lote de imágenes por la red para obtener las predicciones.\n",
        "\n",
        "    * `loss.backward()`: Calcula cómo contribuyó cada peso del modelo al error (backpropagation).\n",
        "\n",
        "    * `optimizer.step()`: Actualiza los pesos del modelo para reducir el error.\n",
        "\n",
        "* Fase de Validación: Después de cada época de entrenamiento, se llama a la función evaluate_model sobre los datos de validación. Esto nos permite monitorizar si el modelo está aprendiendo correctamente y no se está sobreajustando."
      ],
      "metadata": {
        "id": "CACLUHStFe-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Evaluación Final y Visualización 📊\n",
        "\n",
        "Una vez que el entrenamiento ha terminado, esta sección final proporciona un análisis detallado y visual del rendimiento del mejor modelo."
      ],
      "metadata": {
        "id": "FTaim4KwFqWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Realizando Evaluación Final sobre el Conjunto de Prueba ---\")\n",
        "test_loss, test_acc, test_preds, test_labels = evaluate_model(model, test_loader, criterion, DEVICE)\n",
        "print(f\"Resultado Final: Pérdida de Prueba: {test_loss:.4f} | Precisión de Prueba: {test_acc:.4f}\\n\")\n",
        "\n",
        "# Reporte de Clasificación\n",
        "print(\"--- Reporte de Clasificación (Test Set) ---\")\n",
        "print(classification_report(test_labels, test_preds, target_names=CLASS_NAMES, zero_division=0))\n",
        "\n",
        "# Matriz de Confusión\n",
        "print(\"\\n--- Matriz de Confusión (Test Set) ---\")\n",
        "conf_matrix = confusion_matrix(test_labels, test_preds)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Etiqueta Real')\n",
        "plt.title('Matriz de Confusión sobre el Conjunto de Prueba')\n",
        "plt.show()\n",
        "\n",
        "# Gráficas del historial de entrenamiento\n",
        "print(\"\\n--- Visualización del Historial de Entrenamiento ---\")\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history['train_loss'], label='Pérdida de Entrenamiento')\n",
        "plt.plot(history['val_loss'], label='Pérdida de Validación')\n",
        "plt.xlabel('Épocas'); plt.ylabel('Pérdida'); plt.title('Evolución de la Pérdida'); plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history['val_accuracy'], label='Precisión de Validación')\n",
        "plt.xlabel('Épocas'); plt.ylabel('Precisión'); plt.title('Evolución de la Precisión'); plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q1GDTYB7FpRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `evaluate_model(model, test_loader, ...)`: Se llama a la función de evaluación una última vez, pero con los datos de prueba.\n",
        "\n",
        "* `classification_report`: Muestra métricas detalladas como la precisión y el recall para cada clase de madera, permitiéndonos ver si el modelo es mejor reconociendo una especie que otra.\n",
        "\n",
        "* `confusion_matrix`: Se visualiza como un mapa de calor. La diagonal principal muestra los aciertos. Los números fuera de la diagonal muestran los errores de clasificación (por ejemplo, cuántas veces confundió \"cedro\" con \"acacia\").\n",
        "\n",
        "* Gráficas de Historial: Se dibujan las curvas de pérdida y precisión a lo largo de las épocas. Estos gráficos son vitales para diagnosticar cómo fue el entrenamiento y para detectar problemas como el sobreajuste."
      ],
      "metadata": {
        "id": "uGgKxRvvFwtP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bxISv2cOuu5x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}