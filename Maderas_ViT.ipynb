{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1T9L19IRSIldhpTNPuRTGGq0pEEiT7m3j",
      "authorship_tag": "ABX9TyP3BQXjlhXf3dKeHNOxT94k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joseluis-martin/Project-Dendjet/blob/main/Maderas_ViT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Importaciones\n",
        "\n",
        "Este bloque inicial carga todas las \"herramientas\" o librerías que el programa necesita para funcionar."
      ],
      "metadata": {
        "id": "1xfR4vs3_GjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "import timm # La librería clave para Vision Transformers\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "import time\n",
        "import os\n",
        "\n",
        "print(\"PyTorch Version:\", torch.__version__)\n",
        "print(\"Timm Version:\", timm.__version__)"
      ],
      "metadata": {
        "id": "rDXLn1lJ_JDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `torch, torch.nn, torch.optim`: Forman el núcleo de PyTorch. torch se encarga de los tensores (la estructura de datos fundamental), torch.nn (Neural Networks) proporciona las capas de la red neuronal (como la capa de clasificación), y torch.optim contiene los optimizadores (como AdamW) que ajustan el modelo.\n",
        "\n",
        "* `torchvision`: Es la librería de PyTorch para tareas de visión por computador. datasets nos da acceso a ImageFolder, transforms nos permite procesar las imágenes, y models contiene arquitecturas clásicas.\n",
        "\n",
        "* `timm`: (PyTorch Image Models) es una librería externa fundamental para este script. Es la forma más fácil y potente de acceder a cientos de modelos de visión de última generación, incluyendo el Vision Transformer (ViT) que estamos usando.\n",
        "\n",
        "* `DataLoader`: Una utilidad clave de PyTorch que carga los datos en lotes (batches), los mezcla aleatoriamente (shuffle) y puede usar múltiples núcleos de CPU (num_workers) para cargar datos eficientemente.\n",
        "\n",
        "* `numpy`: Una librería para computación numérica. La usamos para convertir los tensores de PyTorch a un formato que scikit-learn pueda entender.\n",
        "\n",
        "* `matplotlib.pyplot` y `seaborn`: Son librerías de visualización. matplotlib es la base para crear gráficos, y seaborn nos permite crear gráficos estadísticos más atractivos, como el mapa de calor de la matriz de confusión.\n",
        "\n",
        "* `sklearn.metrics`: Parte de Scikit-learn, nos proporciona herramientas ya hechas para evaluar el rendimiento del modelo, como classification_report (precisión, recall, f1-score), confusion_matrix, y accuracy_score.\n",
        "\n",
        "* `time` y `os`: Utilidades estándar de Python. time nos permite medir cuánto tarda cada época de entrenamiento, y os nos ayuda a interactuar con el sistema operativo (por ejemplo, para crear carpetas)."
      ],
      "metadata": {
        "id": "YS9j2y54_xU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Configuración y Parámetros ⚙️\n",
        "\n",
        "Esta sección centraliza todas las variables y parámetros que podrías querer ajustar. Tenerlos aquí al principio facilita la experimentación."
      ],
      "metadata": {
        "id": "dGa0EKokAOIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ¡¡IMPORTANTE!! Ajusta estas rutas a nuestro sistema\n",
        "TRAIN_DIR = '/content/drive/MyDrive/Proyecto_Maderas_Sarcofagos/dataset/train'\n",
        "VAL_DIR = '/content/drive/MyDrive/Proyecto_Maderas_Sarcofagos/dataset/val'\n",
        "TEST_DIR = '/content/drive/MyDrive/Proyecto_Maderas_Sarcofagos/dataset/test'\n",
        "\n",
        "# Parámetros del modelo y entrenamiento\n",
        "MODEL_NAME = 'swin_base_patch4_window7_224' # Modelo de ViT a usar\n",
        "NUM_EPOCHS = 15\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "# Configuración del dispositivo (usar GPU si está disponible)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Usando dispositivo: {DEVICE}\")"
      ],
      "metadata": {
        "id": "vnrvWo7GATyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `TRAIN_DIR y VAL_DIR`: Son cadenas de texto que contienen la ruta a tus carpetas de entrenamiento y validación.\n",
        "\n",
        "* `MODEL_NAME`: Es el identificador exacto del modelo que timm va a descargar. 'vit_base_patch16_224' se refiere a un Vision Transformer de tamaño \"base\", que divide la imagen en parches de 16x16 píxeles y fue entrenado con imágenes de 224x224.\n",
        "\n",
        "* `NUM_EPOCHS`: El número de veces que el modelo verá el conjunto de datos de entrenamiento completo.\n",
        "\n",
        "* `BATCH_SIZE`: El número de imágenes que el modelo procesa a la vez antes de actualizar sus pesos. Un batch size más grande puede acelerar el entrenamiento pero consume más memoria de la GPU.\n",
        "\n",
        "* `LEARNING_RATE`: La \"tasa de aprendizaje\". Controla el tamaño de los pasos que da el optimizador para corregir los errores. Es uno de los hiperparámetros más importantes.\n",
        "\n",
        "* `DEVICE`: Este código es \"agnóstico al dispositivo\". Comprueba si tienes una GPU con CUDA disponible (torch.cuda.is_available()) y la selecciona. Si no, usará la CPU. Entrenar en GPU es miles de veces más rápido."
      ],
      "metadata": {
        "id": "D-pipacBAcjR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Preparación de Datos 💾\n",
        "\n",
        "Este bloque se encarga de definir cómo se deben cargar y transformar las imágenes para que sean aptas para el modelo."
      ],
      "metadata": {
        "id": "aupMklSUAsSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformaciones de datos con aumento para el entrenamiento\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Transformaciones para validación (sin aumento de datos)\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Crear datasets\n",
        "# Manejo de error si la ruta no existe\n",
        "try:\n",
        "    train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=train_transforms)\n",
        "    val_dataset = datasets.ImageFolder(VAL_DIR, transform=val_transforms)\n",
        "    test_dataset = datasets.ImageFolder(TEST_DIR, transform=val_transforms)\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Las carpetas del dataset no se encontraron.\")\n",
        "    print(\"Por favor, actualiza las variables TRAIN_DIR y VAL_DIR con las rutas correctas.\")\n",
        "    # Salir o crear datos de prueba si es necesario para que el resto del script no falle\n",
        "    # En un caso real, aquí terminaría la ejecución.\n",
        "    # Para este ejemplo, crearemos datos dummy si la ruta no existe.\n",
        "    if not os.path.exists('path/to/your/dataset/train/class_a'): os.makedirs('path/to/your/dataset/train/class_a')\n",
        "    if not os.path.exists('path/to/your/dataset/val/class_a'): os.makedirs('path/to/your/dataset/val/class_a')\n",
        "    # Crea un archivo de imagen dummy\n",
        "    from PIL import Image\n",
        "    dummy_img = Image.new('RGB', (100, 100), color = 'red')\n",
        "    dummy_img.save('path/to/your/dataset/train/class_a/dummy.png')\n",
        "    dummy_img.save('path/to/your/dataset/val/class_a/dummy.png')\n",
        "    train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=train_transforms)\n",
        "    val_dataset = datasets.ImageFolder(VAL_DIR, transform=val_transforms)\n",
        "    test_dataset = datasets.ImageFolder(TEST_DIR, transform=val_transforms)\n",
        "\n",
        "\n",
        "# Crear DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "# Obtener nombres de las clases y número total de clases\n",
        "CLASS_NAMES = train_dataset.classes\n",
        "NUM_CLASSES = len(CLASS_NAMES)\n",
        "print(f\"Dataset encontrado. Clases: {CLASS_NAMES}\")\n",
        "print(f\"Número de clases: {NUM_CLASSES}\")"
      ],
      "metadata": {
        "id": "ta4ooouTAqv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `transforms.Compose([...])`: Crea una secuencia de transformaciones que se aplicarán a cada imagen.\n",
        "\n",
        "* `train_transforms`: Para los datos de entrenamiento, aplicamos aumento de datos (RandomHorizontalFlip, RandomRotation, ColorJitter) para crear variaciones artificiales y forzar al modelo a aprender las características esenciales de la madera, no la orientación o iluminación específica de una foto.\n",
        "\n",
        "* `val_transforms`: Para la validación, no aplicamos aumento de datos, solo los cambios necesarios (Resize, ToTensor, Normalize) para que las imágenes tengan el formato correcto. Queremos evaluar el modelo en las imágenes originales, sin alterar.\n",
        "\n",
        "* `Resize((224, 224))`: Cambia el tamaño de todas las imágenes a 224x224 píxeles, que es lo que el modelo ViT espera.\n",
        "\n",
        "* `ToTensor()`: Convierte la imagen (píxeles de 0 a 255) a un Tensor de PyTorch (valores de 0.0 a 1.0).\n",
        "\n",
        "* `Normalize(...)`: Estandariza los valores de los píxeles. Las medias y desviaciones estándar usadas son las del dataset ImageNet, donde el modelo fue pre-entrenado. Usar la misma normalización es crucial.\n",
        "\n",
        "* `datasets.ImageFolder(...)`: Esta es la función mágica que crea el dataset. Recorre las carpetas TRAIN_DIR y VAL_DIR, asume que cada subcarpeta es una clase, y asigna etiquetas numéricas automáticamente.\n",
        "\n",
        "* `DataLoader(...)`: Envuelve el dataset y nos permite iterar sobre él en lotes (batch_size) de manera eficiente.\n",
        "\n",
        "* `CLASS_NAMES y NUM_CLASSES`: Extraemos los nombres de las clases (los nombres de las carpetas) y el número total de clases directamente del dataset. Esto hace que el código sea adaptable a cualquier número de maderas que quieras clasificar."
      ],
      "metadata": {
        "id": "-XB8Wi3jAxyM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Definición del Modelo, Función de Pérdida y Optimizador 🧠\n",
        "\n",
        "Aquí es donde construimos las tres piezas centrales del aprendizaje profundo."
      ],
      "metadata": {
        "id": "NQ5g2LYnBN_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el modelo ViT pre-entrenado y adaptarlo a nuestro problema\n",
        "model = timm.create_model(\n",
        "    MODEL_NAME,\n",
        "    pretrained=True,\n",
        "    num_classes=NUM_CLASSES\n",
        ")\n",
        "model.to(DEVICE)\n",
        "\n",
        "# Función de pérdida y optimizador\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "8c5VujGrBG7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `timm.create_model(...)`:\n",
        "    * `pretrained=True`: Es el parámetro más importante. Le dice a timm que descargue no solo la arquitectura del ViT, sino también los pesos pre-entrenados en el dataset ImageNet. Esto nos da un modelo que ya sabe reconocer texturas, bordes y colores.\n",
        "\n",
        "    * `num_classes=NUM_CLASSES`: Adapta el modelo a nuestro problema. Reemplaza la capa final original (que clasificaba 1000 clases de ImageNet) por una nueva capa de clasificación con el número correcto de salidas para nuestras especies de madera.\n",
        "\n",
        "* `criterion = nn.CrossEntropyLoss()`: Define la función de pérdida. Es el estándar para problemas de clasificación multiclase. Mide qué tan \"equivocadas\" están las predicciones del modelo en comparación con las etiquetas reales.\n",
        "\n",
        "* `optimizer = optim.AdamW(...)`: Crea el optimizador. Su trabajo es usar el valor de la pérdida (el error) para calcular cómo ajustar los pesos del modelo para reducir ese error en el siguiente paso. AdamW es una versión mejorada de Adam, muy efectiva para modelos Transformer."
      ],
      "metadata": {
        "id": "omQFU9yFBRLN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Función de Evaluación\n",
        "\n",
        "Esta es una función auxiliar que hemos creado para mantener el código limpio. Su única responsabilidad es medir el rendimiento del modelo en un conjunto de datos, sin entrenarlo."
      ],
      "metadata": {
        "id": "m_tytBerFEIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
        "    return epoch_loss, epoch_acc, all_preds, all_labels"
      ],
      "metadata": {
        "id": "vFyRhUNVFA6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `model.eval()`: Pone el modelo en modo evaluación (desactiva Dropout, etc.).\n",
        "\n",
        "* `with torch.no_grad()`: Desactiva el cálculo de gradientes para acelerar el proceso y ahorrar memoria, ya que aquí no vamos a entrenar.\n",
        "\n",
        "* El resto del código itera sobre los datos, calcula la pérdida y la precisión, y devuelve estos valores."
      ],
      "metadata": {
        "id": "KGYZHVa2FPJ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Bucle Principal de Entrenamiento y Validación 🏋️‍♂️\n",
        "\n",
        "Este es el motor del script, donde el aprendizaje realmente ocurre. Itera varias veces (épocas) sobre los datos."
      ],
      "metadata": {
        "id": "dZqlQItzFXE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = {'train_loss': [], 'val_loss': [], 'val_accuracy': []}\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # --- Fase de Entrenamiento ---\n",
        "    model.train()\n",
        "    running_train_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_train_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
        "    history['train_loss'].append(epoch_train_loss)\n",
        "\n",
        "    # --- Fase de Validación ---\n",
        "    val_loss, val_acc, _, _ = evaluate_model(model, val_loader, criterion, DEVICE)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_accuracy'].append(val_acc)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_duration = end_time - start_time\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | \"\n",
        "          f\"Duración: {epoch_duration:.2f}s | \"\n",
        "          f\"Loss de Entrenamiento: {epoch_train_loss:.4f} | \"\n",
        "          f\"Loss de Validación: {val_loss:.4f} | \"\n",
        "          f\"Precisión de Validación: {val_acc:.4f}\")\n",
        "\n",
        "print(\"\\nEntrenamiento completado.\")"
      ],
      "metadata": {
        "id": "2O0PAY7JFVwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `for epoch in` ...: El bucle externo que controla el número de épocas.\n",
        "\n",
        "* `model.train()`: Pone el modelo en modo entrenamiento, activando capas como Dropout.\n",
        "\n",
        "* Bucle interno for inputs, labels in ...`: Itera sobre cada lote de datos de entrenamiento.\n",
        "\n",
        "* `optimizer.zero_grad()`: Paso crucial. Pone a cero los gradientes calculados en el lote anterior. Si no lo hiciéramos, los gradientes se acumularían.\n",
        "\n",
        "* `outputs = model(inputs)`: El \"forward pass\". Pasa las imágenes a través de la red para obtener las predicciones.\n",
        "\n",
        "* `loss.backward()`: El \"backward pass\". Calcula el gradiente de la pérdida con respecto a cada peso del modelo (backpropagation).\n",
        "\n",
        "* `optimizer.step()`: Usa los gradientes calculados para actualizar los pesos del modelo, moviéndolos en la dirección que reduce el error.\n",
        "\n",
        "* Llamada a `evaluate_model(...)`: Después de cada época de entrenamiento, llamamos a nuestra función para ver cómo se comporta el modelo en el conjunto de validación. Esto nos permite detectar si el modelo está empezando a sobreajustarse."
      ],
      "metadata": {
        "id": "CACLUHStFe-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Evaluación Final y Visualización 📊\n",
        "\n",
        "Una vez que el entrenamiento ha terminado, esta sección final proporciona un análisis detallado y visual del rendimiento del mejor modelo."
      ],
      "metadata": {
        "id": "FTaim4KwFqWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Evaluación sobre el conjunto de prueba (Test Set) ---\n",
        "# Usamos el test_loader para obtener una métrica final y sin sesgos del rendimiento del modelo.\n",
        "print(\"\\n--- Realizando Evaluación Final sobre el Conjunto de Prueba ---\")\n",
        "test_loss, test_acc, test_preds, test_labels = evaluate_model(model, test_loader, criterion, DEVICE)\n",
        "print(f\"Resultado Final: Pérdida de Prueba: {test_loss:.4f} | Precisión de Prueba: {test_acc:.4f}\\n\")\n",
        "\n",
        "\n",
        "# --- Reporte de Clasificación detallado ---\n",
        "print(\"--- Reporte de Clasificación (Test Set) ---\")\n",
        "# Usamos las predicciones y etiquetas del conjunto de prueba para generar el informe.\n",
        "print(classification_report(test_labels, test_preds, target_names=CLASS_NAMES, zero_division=0))\n",
        "\n",
        "\n",
        "# --- Matriz de Confusión ---\n",
        "print(\"\\n--- Matriz de Confusión (Test Set) ---\")\n",
        "conf_matrix = confusion_matrix(test_labels, test_preds)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Etiqueta Real')\n",
        "plt.title('Matriz de Confusión sobre el Conjunto de Prueba')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# --- Gráficas del historial de entrenamiento (Train vs. Validation) ---\n",
        "# Estas gráficas muestran cómo se comportó el modelo durante el proceso de entrenamiento.\n",
        "print(\"\\n--- Visualización del Historial de Entrenamiento ---\")\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Gráfica de Pérdida\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history['train_loss'], label='Pérdida de Entrenamiento')\n",
        "plt.plot(history['val_loss'], label='Pérdida de Validación')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.title('Evolución de la Pérdida durante el Entrenamiento')\n",
        "plt.legend()\n",
        "\n",
        "# Gráfica de Precisión\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history['val_accuracy'], label='Precisión de Validación')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Precisión')\n",
        "plt.title('Evolución de la Precisión durante el Entrenamiento')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q1GDTYB7FpRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `classification_report`: Imprime un informe detallado con métricas clave para cada clase:\n",
        "\n",
        "    * Precision (Precisión): De todas las veces que el modelo predijo \"cedro\", ¿qué porcentaje era correcto?\n",
        "\n",
        "    * Recall (Exhaustividad): De todas las imágenes de \"cedro\" reales, ¿qué porcentaje detectó correctamente el modelo?\n",
        "\n",
        "    * F1-Score: Una media armónica de las dos anteriores, útil para datasets desbalanceados.\n",
        "\n",
        "* `confusion_matrix`: Crea una matriz que nos muestra exactamente dónde se está equivocando el modelo. La diagonal principal son los aciertos. Los números fuera de la diagonal muestran las confusiones (p. ej., cuántas veces clasificó \"acacia\" como \"sicomoro\").\n",
        "\n",
        "* `sns.heatmap`: Crea una visualización en color de la matriz de confusión, que es mucho más fácil de interpretar que una tabla de números.\n",
        "\n",
        "* `plt.plot``\n",
        ": Genera gráficos de líneas que muestran cómo la pérdida y la precisión han evolucionado a lo largo de las épocas. Esto es vital para diagnosticar el entrenamiento (p. ej., si la pérdida de validación empieza a subir, es un claro signo de sobreajuste)."
      ],
      "metadata": {
        "id": "uGgKxRvvFwtP"
      }
    }
  ]
}