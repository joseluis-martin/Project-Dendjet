{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1T9L19IRSIldhpTNPuRTGGq0pEEiT7m3j",
      "authorship_tag": "ABX9TyP3BQXjlhXf3dKeHNOxT94k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joseluis-martin/Project-Dendjet/blob/main/Maderas_ViT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Importaciones\n",
        "\n",
        "Este bloque inicial carga todas las \"herramientas\" o librer铆as que el programa necesita para funcionar."
      ],
      "metadata": {
        "id": "1xfR4vs3_GjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "import timm # La librer铆a clave para Vision Transformers\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "import time\n",
        "import os\n",
        "\n",
        "print(\"PyTorch Version:\", torch.__version__)\n",
        "print(\"Timm Version:\", timm.__version__)"
      ],
      "metadata": {
        "id": "rDXLn1lJ_JDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `torch, torch.nn, torch.optim`: Forman el n煤cleo de PyTorch. torch se encarga de los tensores (la estructura de datos fundamental), torch.nn (Neural Networks) proporciona las capas de la red neuronal (como la capa de clasificaci贸n), y torch.optim contiene los optimizadores (como AdamW) que ajustan el modelo.\n",
        "\n",
        "* `torchvision`: Es la librer铆a de PyTorch para tareas de visi贸n por computador. datasets nos da acceso a ImageFolder, transforms nos permite procesar las im谩genes, y models contiene arquitecturas cl谩sicas.\n",
        "\n",
        "* `timm`: (PyTorch Image Models) es una librer铆a externa fundamental para este script. Es la forma m谩s f谩cil y potente de acceder a cientos de modelos de visi贸n de 煤ltima generaci贸n, incluyendo el Vision Transformer (ViT) que estamos usando.\n",
        "\n",
        "* `DataLoader`: Una utilidad clave de PyTorch que carga los datos en lotes (batches), los mezcla aleatoriamente (shuffle) y puede usar m煤ltiples n煤cleos de CPU (num_workers) para cargar datos eficientemente.\n",
        "\n",
        "* `numpy`: Una librer铆a para computaci贸n num茅rica. La usamos para convertir los tensores de PyTorch a un formato que scikit-learn pueda entender.\n",
        "\n",
        "* `matplotlib.pyplot` y `seaborn`: Son librer铆as de visualizaci贸n. matplotlib es la base para crear gr谩ficos, y seaborn nos permite crear gr谩ficos estad铆sticos m谩s atractivos, como el mapa de calor de la matriz de confusi贸n.\n",
        "\n",
        "* `sklearn.metrics`: Parte de Scikit-learn, nos proporciona herramientas ya hechas para evaluar el rendimiento del modelo, como classification_report (precisi贸n, recall, f1-score), confusion_matrix, y accuracy_score.\n",
        "\n",
        "* `time` y `os`: Utilidades est谩ndar de Python. time nos permite medir cu谩nto tarda cada 茅poca de entrenamiento, y os nos ayuda a interactuar con el sistema operativo (por ejemplo, para crear carpetas)."
      ],
      "metadata": {
        "id": "YS9j2y54_xU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Configuraci贸n y Par谩metros 锔\n",
        "\n",
        "Esta secci贸n centraliza todas las variables y par谩metros que podr铆as querer ajustar. Tenerlos aqu铆 al principio facilita la experimentaci贸n."
      ],
      "metadata": {
        "id": "dGa0EKokAOIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 隆隆IMPORTANTE!! Ajusta estas rutas a nuestro sistema\n",
        "TRAIN_DIR = '/content/drive/MyDrive/Proyecto_Maderas_Sarcofagos/dataset/train'\n",
        "VAL_DIR = '/content/drive/MyDrive/Proyecto_Maderas_Sarcofagos/dataset/val'\n",
        "TEST_DIR = '/content/drive/MyDrive/Proyecto_Maderas_Sarcofagos/dataset/test'\n",
        "\n",
        "# Par谩metros del modelo y entrenamiento\n",
        "MODEL_NAME = 'swin_base_patch4_window7_224' # Modelo de ViT a usar\n",
        "NUM_EPOCHS = 15\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "# Configuraci贸n del dispositivo (usar GPU si est谩 disponible)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Usando dispositivo: {DEVICE}\")"
      ],
      "metadata": {
        "id": "vnrvWo7GATyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `TRAIN_DIR y VAL_DIR`: Son cadenas de texto que contienen la ruta a tus carpetas de entrenamiento y validaci贸n.\n",
        "\n",
        "* `MODEL_NAME`: Es el identificador exacto del modelo que timm va a descargar. 'vit_base_patch16_224' se refiere a un Vision Transformer de tama帽o \"base\", que divide la imagen en parches de 16x16 p铆xeles y fue entrenado con im谩genes de 224x224.\n",
        "\n",
        "* `NUM_EPOCHS`: El n煤mero de veces que el modelo ver谩 el conjunto de datos de entrenamiento completo.\n",
        "\n",
        "* `BATCH_SIZE`: El n煤mero de im谩genes que el modelo procesa a la vez antes de actualizar sus pesos. Un batch size m谩s grande puede acelerar el entrenamiento pero consume m谩s memoria de la GPU.\n",
        "\n",
        "* `LEARNING_RATE`: La \"tasa de aprendizaje\". Controla el tama帽o de los pasos que da el optimizador para corregir los errores. Es uno de los hiperpar谩metros m谩s importantes.\n",
        "\n",
        "* `DEVICE`: Este c贸digo es \"agn贸stico al dispositivo\". Comprueba si tienes una GPU con CUDA disponible (torch.cuda.is_available()) y la selecciona. Si no, usar谩 la CPU. Entrenar en GPU es miles de veces m谩s r谩pido."
      ],
      "metadata": {
        "id": "D-pipacBAcjR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Preparaci贸n de Datos \n",
        "\n",
        "Este bloque se encarga de definir c贸mo se deben cargar y transformar las im谩genes para que sean aptas para el modelo."
      ],
      "metadata": {
        "id": "aupMklSUAsSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformaciones de datos con aumento para el entrenamiento\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Transformaciones para validaci贸n (sin aumento de datos)\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Crear datasets\n",
        "# Manejo de error si la ruta no existe\n",
        "try:\n",
        "    train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=train_transforms)\n",
        "    val_dataset = datasets.ImageFolder(VAL_DIR, transform=val_transforms)\n",
        "    test_dataset = datasets.ImageFolder(TEST_DIR, transform=val_transforms)\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Las carpetas del dataset no se encontraron.\")\n",
        "    print(\"Por favor, actualiza las variables TRAIN_DIR y VAL_DIR con las rutas correctas.\")\n",
        "    # Salir o crear datos de prueba si es necesario para que el resto del script no falle\n",
        "    # En un caso real, aqu铆 terminar铆a la ejecuci贸n.\n",
        "    # Para este ejemplo, crearemos datos dummy si la ruta no existe.\n",
        "    if not os.path.exists('path/to/your/dataset/train/class_a'): os.makedirs('path/to/your/dataset/train/class_a')\n",
        "    if not os.path.exists('path/to/your/dataset/val/class_a'): os.makedirs('path/to/your/dataset/val/class_a')\n",
        "    # Crea un archivo de imagen dummy\n",
        "    from PIL import Image\n",
        "    dummy_img = Image.new('RGB', (100, 100), color = 'red')\n",
        "    dummy_img.save('path/to/your/dataset/train/class_a/dummy.png')\n",
        "    dummy_img.save('path/to/your/dataset/val/class_a/dummy.png')\n",
        "    train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=train_transforms)\n",
        "    val_dataset = datasets.ImageFolder(VAL_DIR, transform=val_transforms)\n",
        "    test_dataset = datasets.ImageFolder(TEST_DIR, transform=val_transforms)\n",
        "\n",
        "\n",
        "# Crear DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "# Obtener nombres de las clases y n煤mero total de clases\n",
        "CLASS_NAMES = train_dataset.classes\n",
        "NUM_CLASSES = len(CLASS_NAMES)\n",
        "print(f\"Dataset encontrado. Clases: {CLASS_NAMES}\")\n",
        "print(f\"N煤mero de clases: {NUM_CLASSES}\")"
      ],
      "metadata": {
        "id": "ta4ooouTAqv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `transforms.Compose([...])`: Crea una secuencia de transformaciones que se aplicar谩n a cada imagen.\n",
        "\n",
        "* `train_transforms`: Para los datos de entrenamiento, aplicamos aumento de datos (RandomHorizontalFlip, RandomRotation, ColorJitter) para crear variaciones artificiales y forzar al modelo a aprender las caracter铆sticas esenciales de la madera, no la orientaci贸n o iluminaci贸n espec铆fica de una foto.\n",
        "\n",
        "* `val_transforms`: Para la validaci贸n, no aplicamos aumento de datos, solo los cambios necesarios (Resize, ToTensor, Normalize) para que las im谩genes tengan el formato correcto. Queremos evaluar el modelo en las im谩genes originales, sin alterar.\n",
        "\n",
        "* `Resize((224, 224))`: Cambia el tama帽o de todas las im谩genes a 224x224 p铆xeles, que es lo que el modelo ViT espera.\n",
        "\n",
        "* `ToTensor()`: Convierte la imagen (p铆xeles de 0 a 255) a un Tensor de PyTorch (valores de 0.0 a 1.0).\n",
        "\n",
        "* `Normalize(...)`: Estandariza los valores de los p铆xeles. Las medias y desviaciones est谩ndar usadas son las del dataset ImageNet, donde el modelo fue pre-entrenado. Usar la misma normalizaci贸n es crucial.\n",
        "\n",
        "* `datasets.ImageFolder(...)`: Esta es la funci贸n m谩gica que crea el dataset. Recorre las carpetas TRAIN_DIR y VAL_DIR, asume que cada subcarpeta es una clase, y asigna etiquetas num茅ricas autom谩ticamente.\n",
        "\n",
        "* `DataLoader(...)`: Envuelve el dataset y nos permite iterar sobre 茅l en lotes (batch_size) de manera eficiente.\n",
        "\n",
        "* `CLASS_NAMES y NUM_CLASSES`: Extraemos los nombres de las clases (los nombres de las carpetas) y el n煤mero total de clases directamente del dataset. Esto hace que el c贸digo sea adaptable a cualquier n煤mero de maderas que quieras clasificar."
      ],
      "metadata": {
        "id": "-XB8Wi3jAxyM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Definici贸n del Modelo, Funci贸n de P茅rdida y Optimizador \n",
        "\n",
        "Aqu铆 es donde construimos las tres piezas centrales del aprendizaje profundo."
      ],
      "metadata": {
        "id": "NQ5g2LYnBN_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el modelo ViT pre-entrenado y adaptarlo a nuestro problema\n",
        "model = timm.create_model(\n",
        "    MODEL_NAME,\n",
        "    pretrained=True,\n",
        "    num_classes=NUM_CLASSES\n",
        ")\n",
        "model.to(DEVICE)\n",
        "\n",
        "# Funci贸n de p茅rdida y optimizador\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "8c5VujGrBG7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `timm.create_model(...)`:\n",
        "    * `pretrained=True`: Es el par谩metro m谩s importante. Le dice a timm que descargue no solo la arquitectura del ViT, sino tambi茅n los pesos pre-entrenados en el dataset ImageNet. Esto nos da un modelo que ya sabe reconocer texturas, bordes y colores.\n",
        "\n",
        "    * `num_classes=NUM_CLASSES`: Adapta el modelo a nuestro problema. Reemplaza la capa final original (que clasificaba 1000 clases de ImageNet) por una nueva capa de clasificaci贸n con el n煤mero correcto de salidas para nuestras especies de madera.\n",
        "\n",
        "* `criterion = nn.CrossEntropyLoss()`: Define la funci贸n de p茅rdida. Es el est谩ndar para problemas de clasificaci贸n multiclase. Mide qu茅 tan \"equivocadas\" est谩n las predicciones del modelo en comparaci贸n con las etiquetas reales.\n",
        "\n",
        "* `optimizer = optim.AdamW(...)`: Crea el optimizador. Su trabajo es usar el valor de la p茅rdida (el error) para calcular c贸mo ajustar los pesos del modelo para reducir ese error en el siguiente paso. AdamW es una versi贸n mejorada de Adam, muy efectiva para modelos Transformer."
      ],
      "metadata": {
        "id": "omQFU9yFBRLN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Funci贸n de Evaluaci贸n\n",
        "\n",
        "Esta es una funci贸n auxiliar que hemos creado para mantener el c贸digo limpio. Su 煤nica responsabilidad es medir el rendimiento del modelo en un conjunto de datos, sin entrenarlo."
      ],
      "metadata": {
        "id": "m_tytBerFEIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
        "    return epoch_loss, epoch_acc, all_preds, all_labels"
      ],
      "metadata": {
        "id": "vFyRhUNVFA6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `model.eval()`: Pone el modelo en modo evaluaci贸n (desactiva Dropout, etc.).\n",
        "\n",
        "* `with torch.no_grad()`: Desactiva el c谩lculo de gradientes para acelerar el proceso y ahorrar memoria, ya que aqu铆 no vamos a entrenar.\n",
        "\n",
        "* El resto del c贸digo itera sobre los datos, calcula la p茅rdida y la precisi贸n, y devuelve estos valores."
      ],
      "metadata": {
        "id": "KGYZHVa2FPJ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Bucle Principal de Entrenamiento y Validaci贸n 锔锔\n",
        "\n",
        "Este es el motor del script, donde el aprendizaje realmente ocurre. Itera varias veces (茅pocas) sobre los datos."
      ],
      "metadata": {
        "id": "dZqlQItzFXE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = {'train_loss': [], 'val_loss': [], 'val_accuracy': []}\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # --- Fase de Entrenamiento ---\n",
        "    model.train()\n",
        "    running_train_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_train_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
        "    history['train_loss'].append(epoch_train_loss)\n",
        "\n",
        "    # --- Fase de Validaci贸n ---\n",
        "    val_loss, val_acc, _, _ = evaluate_model(model, val_loader, criterion, DEVICE)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_accuracy'].append(val_acc)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_duration = end_time - start_time\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | \"\n",
        "          f\"Duraci贸n: {epoch_duration:.2f}s | \"\n",
        "          f\"Loss de Entrenamiento: {epoch_train_loss:.4f} | \"\n",
        "          f\"Loss de Validaci贸n: {val_loss:.4f} | \"\n",
        "          f\"Precisi贸n de Validaci贸n: {val_acc:.4f}\")\n",
        "\n",
        "print(\"\\nEntrenamiento completado.\")"
      ],
      "metadata": {
        "id": "2O0PAY7JFVwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `for epoch in` ...: El bucle externo que controla el n煤mero de 茅pocas.\n",
        "\n",
        "* `model.train()`: Pone el modelo en modo entrenamiento, activando capas como Dropout.\n",
        "\n",
        "* Bucle interno for inputs, labels in ...`: Itera sobre cada lote de datos de entrenamiento.\n",
        "\n",
        "* `optimizer.zero_grad()`: Paso crucial. Pone a cero los gradientes calculados en el lote anterior. Si no lo hici茅ramos, los gradientes se acumular铆an.\n",
        "\n",
        "* `outputs = model(inputs)`: El \"forward pass\". Pasa las im谩genes a trav茅s de la red para obtener las predicciones.\n",
        "\n",
        "* `loss.backward()`: El \"backward pass\". Calcula el gradiente de la p茅rdida con respecto a cada peso del modelo (backpropagation).\n",
        "\n",
        "* `optimizer.step()`: Usa los gradientes calculados para actualizar los pesos del modelo, movi茅ndolos en la direcci贸n que reduce el error.\n",
        "\n",
        "* Llamada a `evaluate_model(...)`: Despu茅s de cada 茅poca de entrenamiento, llamamos a nuestra funci贸n para ver c贸mo se comporta el modelo en el conjunto de validaci贸n. Esto nos permite detectar si el modelo est谩 empezando a sobreajustarse."
      ],
      "metadata": {
        "id": "CACLUHStFe-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Evaluaci贸n Final y Visualizaci贸n \n",
        "\n",
        "Una vez que el entrenamiento ha terminado, esta secci贸n final proporciona un an谩lisis detallado y visual del rendimiento del mejor modelo."
      ],
      "metadata": {
        "id": "FTaim4KwFqWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Evaluaci贸n sobre el conjunto de prueba (Test Set) ---\n",
        "# Usamos el test_loader para obtener una m茅trica final y sin sesgos del rendimiento del modelo.\n",
        "print(\"\\n--- Realizando Evaluaci贸n Final sobre el Conjunto de Prueba ---\")\n",
        "test_loss, test_acc, test_preds, test_labels = evaluate_model(model, test_loader, criterion, DEVICE)\n",
        "print(f\"Resultado Final: P茅rdida de Prueba: {test_loss:.4f} | Precisi贸n de Prueba: {test_acc:.4f}\\n\")\n",
        "\n",
        "\n",
        "# --- Reporte de Clasificaci贸n detallado ---\n",
        "print(\"--- Reporte de Clasificaci贸n (Test Set) ---\")\n",
        "# Usamos las predicciones y etiquetas del conjunto de prueba para generar el informe.\n",
        "print(classification_report(test_labels, test_preds, target_names=CLASS_NAMES, zero_division=0))\n",
        "\n",
        "\n",
        "# --- Matriz de Confusi贸n ---\n",
        "print(\"\\n--- Matriz de Confusi贸n (Test Set) ---\")\n",
        "conf_matrix = confusion_matrix(test_labels, test_preds)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
        "plt.xlabel('Predicci贸n')\n",
        "plt.ylabel('Etiqueta Real')\n",
        "plt.title('Matriz de Confusi贸n sobre el Conjunto de Prueba')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# --- Gr谩ficas del historial de entrenamiento (Train vs. Validation) ---\n",
        "# Estas gr谩ficas muestran c贸mo se comport贸 el modelo durante el proceso de entrenamiento.\n",
        "print(\"\\n--- Visualizaci贸n del Historial de Entrenamiento ---\")\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Gr谩fica de P茅rdida\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history['train_loss'], label='P茅rdida de Entrenamiento')\n",
        "plt.plot(history['val_loss'], label='P茅rdida de Validaci贸n')\n",
        "plt.xlabel('pocas')\n",
        "plt.ylabel('P茅rdida')\n",
        "plt.title('Evoluci贸n de la P茅rdida durante el Entrenamiento')\n",
        "plt.legend()\n",
        "\n",
        "# Gr谩fica de Precisi贸n\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history['val_accuracy'], label='Precisi贸n de Validaci贸n')\n",
        "plt.xlabel('pocas')\n",
        "plt.ylabel('Precisi贸n')\n",
        "plt.title('Evoluci贸n de la Precisi贸n durante el Entrenamiento')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q1GDTYB7FpRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `classification_report`: Imprime un informe detallado con m茅tricas clave para cada clase:\n",
        "\n",
        "    * Precision (Precisi贸n): De todas las veces que el modelo predijo \"cedro\", 驴qu茅 porcentaje era correcto?\n",
        "\n",
        "    * Recall (Exhaustividad): De todas las im谩genes de \"cedro\" reales, 驴qu茅 porcentaje detect贸 correctamente el modelo?\n",
        "\n",
        "    * F1-Score: Una media arm贸nica de las dos anteriores, 煤til para datasets desbalanceados.\n",
        "\n",
        "* `confusion_matrix`: Crea una matriz que nos muestra exactamente d贸nde se est谩 equivocando el modelo. La diagonal principal son los aciertos. Los n煤meros fuera de la diagonal muestran las confusiones (p. ej., cu谩ntas veces clasific贸 \"acacia\" como \"sicomoro\").\n",
        "\n",
        "* `sns.heatmap`: Crea una visualizaci贸n en color de la matriz de confusi贸n, que es mucho m谩s f谩cil de interpretar que una tabla de n煤meros.\n",
        "\n",
        "* `plt.plot``\n",
        ": Genera gr谩ficos de l铆neas que muestran c贸mo la p茅rdida y la precisi贸n han evolucionado a lo largo de las 茅pocas. Esto es vital para diagnosticar el entrenamiento (p. ej., si la p茅rdida de validaci贸n empieza a subir, es un claro signo de sobreajuste)."
      ],
      "metadata": {
        "id": "uGgKxRvvFwtP"
      }
    }
  ]
}